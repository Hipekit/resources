# 基本概念

| 概念                 | 数据库对照 | 说明                                                         |
| -------------------- | ---------- | ------------------------------------------------------------ |
| 索引库（indices）    | Datebases  | indices是index的复数，代表许多的索引                         |
| 类型（Types）        | Tables     | 6.0已弃用，7.0开始一个Index对应一个Type                      |
| 文档（document）     | Rows       | 存入索引库原始的数据，以JSON格式存储。比如一条商品信息       |
| 字段（field）        | Columns    | 文档中的属性                                                 |
| 映射配置（mappings） |            | 字段的数据类型、属性、是否索引、是否存储等特性               |
| 分片（shard）        |            | 数据拆分后的各个部分                                         |
| 副本（replica）      |            | 每个分片的复制                                               |
| 集群（cluster）      |            | 由一个或多个节点组成，共同拥有整个数据，一起提供索引和搜索功能。集群默认名为“elasticsearch” |
| 节点（node）         |            | 集群中的一个服务器，用于存储数据，参与集群的索引和搜索功能   |

**注：Elasticsearch本身就是分布式的，因此即便你只有一个节点，Elasticsearch默认也会对你的数据进行分片和副本操作，当你向集群添加新数据时，数据也会在新加入的节点中进行平衡。**

> 集群：可以通过修改配置文件或命令行`-E cluster.name = 节点名 `指定

## 1、集群

###  1.1、集群的健康状态

```http
GET _cluster/health
```

* Green：主分片和副本都分配正常
* Yellow：主分片都分片正常，有副本分片未能正常分配
* Red：有主分片未能分配

## 2、节点

节点本质是一个Java进程，一台机器可以运行多个ES实例，但生产环境一台机器建议只运行一个节点，可以通过配置文件或命令行`-E node.name = 节点名`指定。每个节点在启动之后，会分配一个UID，保存在data目录下。

### 2.1、Master eligible和Master节点

每个节点启动的时候，默认是一个`Master eligible`节点（可以通过设置`node.master:flase`禁止）。`Master eligible`可以参加选主流程，成为`Master`节点。

每一个节点都保存了集群的状态，但是只有`Master`节点可以修改集群的状态信息。

* 集群的状态保存了一个集群中的必要信息，包括
  * 所有的节点信息
  * 所有的索引和其相关的Mapping和Setting信息
  * 分片的路由信息

* 之所以只有`Master`节点可以修改集群信息，是因为如果任意的节点都能修改那会导致数据的不一致性

### 2.2、Data节点

用于保存分片数据，在数据扩展上起着至关重要的作用。

### 2.3、Coordinating节点

负责接收Clinet的请求，将这些请求分发到合适的节点上，最终把结果汇集到一起返回。

每个节点默认起到了`Coordinating`节点的职责

## 3、分片

* 主分片：`Paimary Shard`用于解决数据水平扩展的问题，通过主分片，可以将数据分布到集群内所有的节点上
  * 一个分片就是一个`Lucene`实例
  * 主分片在索引创建时指定，后续不允许修改，除非`Reinex`

* 副本，解决数据高可用的问题，是主分片的拷贝
  * 副本分片数可用动态调整
  * 增加副本数可以在一定程度上提高服务的可用性（读取的吞吐）

## 4、文档的CRUD

### 4.1、创建索引

* 支持自动生成文档ID和指定文档ID两种方式
* 通过调用`post /users/_doc`，系统会自动生成文档id
* 通过`PUT create`一个指定ID的文档时，如果ID已存在，会报错

> post方式不需要指定文档ID，而PUT需要指定

#### 示例

Post方式：

```http
POST users/_doc
{
"name":"Join"
}
```

PUT方式：

```http
PUT users/_create/1
{
  "name":"Join"
}
```

`PUT`使用普通_doc时，可在路由后面加`optype`参数

```http
PUT users/_doc1?optype=create
{
	"name":"Jack"
}
```



### 4.2、Get

* 查询到文档，返回HTTP 200
  * 文档元信息
    * _index / _type
    * 版本信息，同一个ID的文档，即使被删除，version也会不断增加
    * _source中默认包含原始文档的所有信息

* 查询不到，返回HTTP 404

#### 示例

```http
Get users/_doc/1
```

### 4.3、Index

index也是增加一个文档，但和create不同的是如果文档存在，会删除原来的文档，然后索引新文档，version加1。

```http
PUT users/_doc/1
{
  "user":"Jack1",
  "post_date":"2019-04-16T14:12:12",
  "message":"trying out Elasticsearch"
}
```

### 4.4、Update

`update`不会删除原来的方法，是实现增量更新。采用`POST`方式，`Payload`需要包含在`doc`中

```http
POST users/_update/1
{
	"doc":{
		"albums":["Album1","Album2"]
	}
}
```

## 5、批量操作

### 5.1、Bulk API

`Bukl API`支持数据的批量操作，且可以是不同类型的操作。包括

* create
* index
* update
* delete

可以在URL中指定Index，也可以在Payload中进行。

Elasticsearch不支持事务，所以操作中单条失败不会影响其他操作，返回结果中包含每一条的执行结果。

每种操作需要指定`_index`、`_type`和`_id`这些元数据

```http
POST _bulk
{ "index" : { "_index" : "test", "_id" : "1" } }
{ "field1" : "value1" }
{ "delete" : { "_index" : "test", "_id" : "2" } }
{ "create" : { "_index" : "test2", "_id" : "3" } }
{ "field1" : "value3" }
{ "update" : {"_id" : "1", "_index" : "test"} }
{ "doc" : {"field2" : "value2"} }
```

> index和create需要在下一行提供请求数据（文档数据）
>
> delete不需要
>
> update支持doc、upsert、script等

### 5.2、批量读取mget

```http
GET _mget
{
  "docs":[
    {
      "_index":"users",
      "_id":"1"
    },
    {
      "_index":"users",
      "_id":"2"
    }
    ]
}
```

### 5.3、批量查询msearch

```http
POST kibana_sample_data_ecommerce/_msearch
{}
{"query" : {"match_all" : {}},"size":1}
{"index" : "kibana_sample_data_flights"}
{"query" : {"match_all" : {}},"size":2}
```

